{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Lab 4\n",
    "\n",
    "\n",
    "# Linear Regression from scratch\n",
    "\n",
    "## 24th February 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Regression function :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "\n",
    "    def __init__(self, lr=0.01, n_iters=1000):\n",
    "        self.lr = lr\n",
    "        self.n_iters = n_iters\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        '''\n",
    "        Fit method takes the features `X` and `y` target\n",
    "        build a linear model and calculate the weights and bias\n",
    "        dynamically using `dw` and `db` and update the weights\n",
    "        and bias using gradient descenting. \n",
    "        '''\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        # initalize the weights and bias\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "\n",
    "\n",
    "        # Start the learn algorithm gradient descenting\n",
    "        for _ in range(self.n_iters):\n",
    "            y_predicted = np.dot(X, self.weights) + self.bias\n",
    "\n",
    "            # Compute the weights and bias dynamically \n",
    "            dw = (1 / n_samples) * np.dot(X.T, (y_predicted - y))\n",
    "            db = (1 / n_samples) * np.sum(y_predicted - y)\n",
    "\n",
    "            # Update the weights and bias with actual\n",
    "            self.weights -= self.lr * dw\n",
    "            self.bias -= self.lr * db\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_predicted = np.dot(X, self.weights) + self.bias\n",
    "        return np.array(y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For error calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importing for data and dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_least = {}\n",
    "lr = 0.001\n",
    "n_iters = 500\n",
    "param = 1\n",
    "\n",
    "for i in range(1,21):\n",
    "    X, y = datasets.make_regression(n_samples=100, n_features=i, noise=20, random_state=42)\n",
    "    # Lets split the dataset into 80 training and 20 testing examples\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5827)\n",
    "    \n",
    "    mse_featureWise = {}\n",
    "    lr = 0.001\n",
    "    n_iters = 500\n",
    "    \n",
    "    for j in range(1,21):\n",
    "        clf = LinearRegression(lr, n_iters)\n",
    "        clf.fit(X_train, y_train)\n",
    "        prediction = clf.predict(X_test)\n",
    "        mse = mean_squared_error(y_test, prediction)\n",
    "        mse_featureWise[mse] = [lr,n_iters]\n",
    "        \n",
    "        lr = lr+0.001\n",
    "        n_iters = n_iters + 500\n",
    "        \n",
    "    mse_least[i] = [min(mse_featureWise),mse_featureWise[min(mse_featureWise)][0],mse_featureWise[min(mse_featureWise)][1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mimimum mean square is recorded for a particular parameter number, and its corresponding learning rate and number of iterations i.e for the minimum mse is recorded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(mse_least)\n",
    "df = pd.DataFrame(mse_least, index = ['MSE(Minimum)','Learning Rate','Iteration'])\n",
    "df = df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    MSE(Minimum)  Learning Rate  Iteration\n",
      "1     444.178659          0.020    10000.0\n",
      "2     267.969718          0.020    10000.0\n",
      "3     366.274741          0.003     1500.0\n",
      "4     547.514503          0.003     1500.0\n",
      "5     267.907681          0.020    10000.0\n",
      "6     416.661736          0.003     1500.0\n",
      "7     567.408307          0.003     1500.0\n",
      "8     366.825518          0.010     5000.0\n",
      "9     347.928085          0.020    10000.0\n",
      "10    270.409403          0.020    10000.0\n",
      "11    446.614999          0.005     2500.0\n",
      "12    614.992648          0.020    10000.0\n",
      "13    263.259364          0.020    10000.0\n",
      "14    504.872197          0.004     2000.0\n",
      "15    654.090726          0.008     4000.0\n",
      "16    369.689885          0.020    10000.0\n",
      "17    645.174056          0.020    10000.0\n",
      "18    218.967862          0.020    10000.0\n",
      "19    620.478774          0.020    10000.0\n",
      "20    887.962472          0.007     3500.0\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    MSE(Minimum)  Learning Rate  Iteration\n",
      "18    218.967862          0.020    10000.0\n",
      "13    263.259364          0.020    10000.0\n",
      "5     267.907681          0.020    10000.0\n",
      "2     267.969718          0.020    10000.0\n",
      "10    270.409403          0.020    10000.0\n",
      "9     347.928085          0.020    10000.0\n",
      "3     366.274741          0.003     1500.0\n",
      "8     366.825518          0.010     5000.0\n",
      "16    369.689885          0.020    10000.0\n",
      "6     416.661736          0.003     1500.0\n",
      "1     444.178659          0.020    10000.0\n",
      "11    446.614999          0.005     2500.0\n",
      "14    504.872197          0.004     2000.0\n",
      "4     547.514503          0.003     1500.0\n",
      "7     567.408307          0.003     1500.0\n",
      "12    614.992648          0.020    10000.0\n",
      "19    620.478774          0.020    10000.0\n",
      "17    645.174056          0.020    10000.0\n",
      "15    654.090726          0.008     4000.0\n",
      "20    887.962472          0.007     3500.0\n"
     ]
    }
   ],
   "source": [
    "df.sort_values(by=['MSE(Minimum)'], inplace=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the minimum error we got was with 18 parameters, learning rate of 0.020 and 10000 iterations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
